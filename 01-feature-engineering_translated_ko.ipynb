{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10fb0d93",
   "metadata": {},
   "source": [
    "# 플레이어 이탈 데이터셋을 위한 특성 공학\n",
    "\n",
    "이 노트북은 player_churn.csv 데이터셋에 대한 특성 공학을 수행하여 추가 분석을 위해 특정 열을 선택합니다. 특성 공학은 머신 러닝 파이프라인에서 가장 관련성 높은 특성을 선택하여 모델 성능을 향상시키는 중요한 단계입니다.\n",
    "\n",
    "이 노트북에서는 다음 사항에 중점을 둘 것입니다:\n",
    "1. 플레이어 이탈 데이터셋 로드\n",
    "2. 도메인 지식을 기반으로 가장 중요한 특성 선택\n",
    "3. 선택된 특성 탐색\n",
    "4. 모델 훈련을 위한 처리된 데이터셋 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340ee578",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn \"pandas>=2.0.0\" s3fs==0.4.2 sagemaker xgboost mlflow==2.13.2 sagemaker-mlflow==0.1.0 seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f35cf",
   "metadata": {},
   "source": [
    "## 환경 설정\n",
    "\n",
    "먼저, 데이터 조작, 분석 및 시각화를 위한 필요한 라이브러리를 가져오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e883c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "import boto3\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d9dd9b",
   "metadata": {},
   "source": [
    "## 데이터셋 로드\n",
    "\n",
    "플레이어 행동 데이터와 이탈 정보가 포함된 player_churn.csv 파일을 로드하겠습니다. 이 데이터셋에는 플레이어 세션, 참여 패턴 및 이탈 여부(게임 중단)에 관한 다양한 지표가 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data/player_churn.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec76071",
   "metadata": {},
   "source": [
    "## 특성 공학\n",
    "\n",
    "이 단계에서는 이탈 예측 모델에 가장 관련성 있는 특성만 선택하겠습니다. 이러한 특성들은 도메인 전문 지식이나 이전 분석을 통해 플레이어 이탈을 예측하는 데 가장 효과적인 것으로 확인되었을 가능성이 높습니다.\n",
    "\n",
    "선택된 특성에는 다음이 포함됩니다:\n",
    "- 플레이어 식별 특성(`player_id`, `cohort_id`, `player_type`)\n",
    "- 시간적 특성(`cohort_day_of_week`)\n",
    "- 참여 지표(`player_lifetime`, `session_count`)\n",
    "- 세션 타이밍 패턴(다양한 시간대 지표)\n",
    "- 타겟 변수(`player_churn`)\n",
    "\n",
    "이러한 특정 특성에 집중함으로써 더 효율적이고 해석 가능한 모델을 구축할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb99098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to keep\n",
    "cols = ['cohort_day_of_week',\n",
    "       'begin_session_time_of_day_std_last_week_1',\n",
    "       'player_lifetime',\n",
    "       'begin_session_time_of_day_mean_last_day_1',\n",
    "       'end_session_time_of_day_mean_last_week_1',\n",
    "       'begin_session_time_of_day_mean_last_week_1',\n",
    "       'cohort_id',\n",
    "       'player_type',\n",
    "       'begin_session_time_of_day_std_last_day_1',\n",
    "       'end_session_time_of_day_mean_last_day_1',\n",
    "       'begin_session_time_of_day_mean_last_day_2',\n",
    "       'end_session_time_of_day_std_last_week_1',\n",
    "       'end_session_time_of_day_std_last_day_1',\n",
    "       'session_count',\n",
    "       'end_session_time_of_day_mean_last_day_3',\n",
    "       'begin_session_time_of_day_mean_last_day_3',\n",
    "       'end_session_time_of_day_mean_last_day_2',\n",
    "       'player_churn',\n",
    "       'player_id']\n",
    "\n",
    "# Check if all columns exist in the dataset\n",
    "missing_cols = [col for col in cols if col not in df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Warning: The following columns are not in the dataset: {missing_cols}\")\n",
    "    # Keep only columns that exist in the dataset\n",
    "    cols = [col for col in cols if col in df.columns]\n",
    "\n",
    "# Select only the specified columns\n",
    "df_selected = df[cols]\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(f\"Selected dataset shape: {df_selected.shape}\")\n",
    "df_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53692801",
   "metadata": {},
   "source": [
    "## 결측값 처리\n",
    "\n",
    "특정 시간대 표준 편차 특성의 경우, 결측값을 0으로 채우겠습니다. 이는 결측값이 세션 시간의 변동이 없음을 나타낼 가능성이 높기 때문에(예: 세션이 하나뿐이거나 일관된 세션 시간) 이러한 특성에 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f26b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to fill with 0\n",
    "fill_zero_cols = [\n",
    "    'begin_session_time_of_day_std_last_week_1',\n",
    "    'begin_session_time_of_day_std_last_day_1',\n",
    "    'end_session_time_of_day_std_last_week_1',\n",
    "    'end_session_time_of_day_std_last_day_1'\n",
    "]\n",
    "\n",
    "# Fill missing values with 0 for specified columns\n",
    "for col in fill_zero_cols:\n",
    "    if col in df_selected.columns:\n",
    "        # Count missing values before filling\n",
    "        missing_count = df_selected[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            print(f\"Filling {missing_count} missing values with 0 in column: {col}\")\n",
    "            df_selected.loc[:, col] = df_selected[col].fillna(0)\n",
    "\n",
    "# Verify the missing values were filled\n",
    "missing_after = {col: df_selected[col].isnull().sum() for col in fill_zero_cols if col in df_selected.columns}\n",
    "print(\"\\nRemaining missing values after filling:\")\n",
    "for col, count in missing_after.items():\n",
    "    print(f\"{col}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb09b97",
   "metadata": {},
   "source": [
    "## 원-핫 인코딩\n",
    "\n",
    "범주형 변수에 원-핫 인코딩을 적용하여 머신 러닝 알고리즘에 제공할 수 있는 형식으로 변환하겠습니다. 이 과정은 원래 범주형 열의 각 카테고리에 대한 이진 열을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce383e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in categorical columns before encoding\n",
    "if 'player_type' in df_selected.columns:\n",
    "    print(f\"Unique values in player_type: {df_selected['player_type'].nunique()}\")\n",
    "    print(df_selected['player_type'].value_counts())\n",
    "    \n",
    "if 'cohort_id' in df_selected.columns:\n",
    "    print(f\"\\nUnique values in cohort_id: {df_selected['cohort_id'].nunique()}\")\n",
    "    print(df_selected['cohort_id'].value_counts().head())  # Show only top values if many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoding\n",
    "# Create dummy variables for player_type and cohort_id\n",
    "cols_to_encode = ['player_type', 'cohort_id']\n",
    "encoded_cols = [col for col in cols_to_encode if col in df_selected.columns]\n",
    "\n",
    "if encoded_cols:\n",
    "    # Get one-hot encoding\n",
    "    df_encoded = pd.get_dummies(df_selected, columns=encoded_cols, prefix=encoded_cols, dtype=int)\n",
    "    \n",
    "    # Display information about the encoded dataset\n",
    "    print(f\"Shape before encoding: {df_selected.shape}\")\n",
    "    print(f\"Shape after encoding: {df_encoded.shape}\")\n",
    "    print(f\"New columns added: {df_encoded.shape[1] - df_selected.shape[1]}\")\n",
    "    \n",
    "    # Update our working dataframe\n",
    "    df_selected = df_encoded\n",
    "    \n",
    "    # Show a sample of the encoded columns\n",
    "    encoded_column_names = [col for col in df_selected.columns if any(col.startswith(prefix + '_') for prefix in encoded_cols)]\n",
    "    print(\"\\nSample of encoded columns:\")\n",
    "    print(encoded_column_names[:10])  # Show first 10 encoded columns\n",
    "    \n",
    "    # Display the first few rows of the encoded dataframe\n",
    "    df_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5328368",
   "metadata": {},
   "source": [
    "## 특성 선택 후 데이터 탐색\n",
    "\n",
    "이제 특성을 선택하고, 결측값을 처리하고, 범주형 변수를 인코딩했으니 데이터셋을 탐색하여 작업할 데이터를 더 잘 이해해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bc96b7",
   "metadata": {},
   "source": [
    "### 결측값 분석\n",
    "\n",
    "선택한 특성에 남아있는 결측값이 있는지 확인해 보겠습니다. 결측값은 모델 성능에 상당한 영향을 미칠 수 있으므로 적절하게 처리해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df_selected.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f305559a",
   "metadata": {},
   "source": [
    "### 통계 요약\n",
    "\n",
    "수치형 특성의 기본 통계를 살펴보고 분포, 범위 및 잠재적 이상치를 이해해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics of numerical columns\n",
    "df_selected.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d833b",
   "metadata": {},
   "source": [
    "### 타겟 변수 분석\n",
    "\n",
    "타겟 변수(player_churn)의 분포를 이해하는 것은 모델 개발에 중요합니다. 불균형한 분포는 모델 훈련 중에 특별한 처리 기법이 필요할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable\n",
    "if 'player_churn' in df_selected.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(x='player_churn', data=df_selected)\n",
    "    plt.title('Distribution of Player Churn')\n",
    "    plt.xlabel('Player Churn (0 = No, 1 = Yes)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate churn rate\n",
    "    churn_rate = df_selected['player_churn'].mean() * 100\n",
    "    print(f\"Churn rate: {churn_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461431d2",
   "metadata": {},
   "source": [
    "## 데이터셋 균형 맞추기\n",
    "\n",
    "모델 성능을 향상시키기 위해 랜덤 오버샘플링을 사용하여 데이터셋의 균형을 맞추겠습니다. 이 기법은 소수 클래스(이탈한 플레이어)의 샘플을 무작위로 복제하여 클래스 간 1:1 비율을 달성하는 것을 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df_selected[df_selected['player_churn'] == 0]\n",
    "df_minority = df_selected[df_selected['player_churn'] == 1]\n",
    "\n",
    "print(f\"Before oversampling:\\n\"\n",
    "      f\"Number of non-churned players (majority): {len(df_majority)}\\n\"\n",
    "      f\"Number of churned players (minority): {len(df_minority)}\")\n",
    "\n",
    "# Oversample minority class\n",
    "df_minority_oversampled = resample(df_minority, \n",
    "                                   replace=True,     # sample with replacement\n",
    "                                   n_samples=len(df_majority),    # match majority class\n",
    "                                   random_state=42)  # reproducible results\n",
    "\n",
    "# Combine majority class with oversampled minority class\n",
    "df_balanced = pd.concat([df_majority, df_minority_oversampled])\n",
    "\n",
    "# Display new class distribution\n",
    "print(f\"\\nAfter oversampling:\\n\"\n",
    "      f\"Number of non-churned players: {len(df_balanced[df_balanced['player_churn'] == 0])}\\n\"\n",
    "      f\"Number of churned players: {len(df_balanced[df_balanced['player_churn'] == 1])}\")\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Visualize the balanced distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='player_churn', data=df_balanced)\n",
    "plt.title('Distribution of Player Churn After Balancing')\n",
    "plt.xlabel('Player Churn (0 = No, 1 = Yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc14549",
   "metadata": {},
   "source": [
    "## 데이터 타입 변환\n",
    "\n",
    "일부 머신 러닝 알고리즘은 특정 데이터 타입을 요구합니다. 여기서는 타겟 변수를 불리언에서 정수(long) 형식으로 변환하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d190526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current data type of player_churn\n",
    "print(f\"Current data type of player_churn: {df_balanced['player_churn'].dtype}\")\n",
    "\n",
    "# Convert player_churn from boolean to long (int64)\n",
    "df_balanced['player_churn'] = df_balanced['player_churn'].astype('int64')\n",
    "\n",
    "# Verify the conversion\n",
    "print(f\"New data type of player_churn: {df_balanced['player_churn'].dtype}\")\n",
    "\n",
    "# Display a sample of the data to confirm\n",
    "print(\"\\nSample values after conversion:\")\n",
    "print(df_balanced['player_churn'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0124c49a",
   "metadata": {},
   "source": [
    "## SageMaker Feature Store에 저장\n",
    "\n",
    "이제 처리된 데이터셋을 머신 러닝 워크플로우에서 사용하기 위해 Amazon SageMaker Feature Store에 저장하겠습니다. Feature Store는 특성을 위한 중앙 저장소를 제공하여 팀과 프로젝트 간에 특성을 더 쉽게 공유하고 재사용할 수 있게 합니다.\n",
    "\n",
    "### SageMaker Feature Store란 무엇인가?\n",
    "\n",
    "Amazon SageMaker Feature Store는 특성을 저장하고 액세스할 수 있는 목적별 저장소로, 팀 간에 특성을 더 쉽게 이름 지정, 구성 및 재사용할 수 있습니다. 주요 이점은 다음과 같습니다:\n",
    "\n",
    "- **특성 재사용**: 특성을 한 번 저장하고 여러 모델에서 재사용\n",
    "- **일관성**: 훈련과 추론 간에 일관된 특성 변환 보장\n",
    "- **발견 가능성**: 조직 전체에서 특성을 발견하고 공유 가능\n",
    "- **실시간 액세스**: 온라인 추론을 위한 낮은 지연 시간으로 특성 액세스\n",
    "- **과거 액세스**: 훈련 및 백테스팅을 위한 특정 시점의 특성 값 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SageMaker Feature Store modules\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition, FeatureTypeEnum\n",
    "\n",
    "# Initialize SageMaker session\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "s3_bucket_name = session.default_bucket()\n",
    "prefix = \"player-churn-feature-store\"\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"SageMaker session initialized in region: {region}\")\n",
    "print(f\"Using S3 bucket: {s3_bucket_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbb52c0",
   "metadata": {},
   "source": [
    "### Feature Store를 위한 데이터 준비\n",
    "\n",
    "SageMaker Feature Store는 두 개의 특수 열이 필요합니다:\n",
    "1. 각 레코드를 고유하게 식별하는 **레코드 식별자** 열(여기서는 `player_id` 사용)\n",
    "2. 특성 값이 생성된 시점을 나타내는 **이벤트 시간** 열\n",
    "\n",
    "데이터셋에 이벤트 시간 열을 추가하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1370a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table is available as variable `df`\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def generate_event_timestamp():\n",
    "    # naive datetime representing local time\n",
    "    naive_dt = datetime.now()\n",
    "    # take timezone into account\n",
    "    aware_dt = naive_dt.astimezone()\n",
    "    # time in UTC\n",
    "    utc_dt = aware_dt.astimezone(timezone.utc)\n",
    "    # transform to ISO-8601 format\n",
    "    event_time = utc_dt.isoformat(timespec='milliseconds')\n",
    "    event_time = event_time.replace('+00:00', 'Z')\n",
    "    return event_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'EventTime' with the current timestamp. This will be used as the event time for the feature store.\n",
    "dt = generate_event_timestamp()\n",
    "df_balanced['event_time'] = dt\n",
    "\n",
    "# Define feature group name\n",
    "feature_group_name = \"player-churn-features-\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "# Create Feature Group\n",
    "player_churn_feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=session)\n",
    "\n",
    "# Load the data into Feature Store\n",
    "player_churn_feature_group.load_feature_definitions(data_frame=df_balanced)\n",
    "print(f\"Feature group name: {feature_group_name}\")\n",
    "print(\"Feature definitions loaded from dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d394013",
   "metadata": {},
   "source": [
    "### 특성 그룹 생성\n",
    "\n",
    "이제 SageMaker Feature Store에 특성 그룹을 생성하겠습니다. 다음과 같이 구성하겠습니다:\n",
    "- 오프라인 저장을 위한 S3 위치\n",
    "- 레코드 식별자 열(`player_id`)\n",
    "- 이벤트 시간 열(`EventTime`)\n",
    "- 낮은 지연 시간 액세스를 위한 온라인 스토어 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d186e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature group\n",
    "player_churn_feature_group.create(\n",
    "    s3_uri=f\"s3://{s3_bucket_name}/{prefix}\",\n",
    "    record_identifier_name=\"player_id\",\n",
    "    event_time_feature_name=\"event_time\",\n",
    "    role_arn=role,\n",
    "    enable_online_store=True\n",
    ")\n",
    "\n",
    "# Wait for feature group creation to complete\n",
    "# player_churn_feature_group.wait()\n",
    "# print(f\"Feature group {feature_group_name} created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bdb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    \"\"\"Helper function to wait for the completions of creating a feature group\"\"\"\n",
    "    response = feature_group.describe()\n",
    "    status = response.get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        response = feature_group.describe()\n",
    "        status = response.get(\"FeatureGroupStatus\")\n",
    "\n",
    "    if status != \"Created\":\n",
    "        print(f\"Failed to create feature group, response: {response}\")\n",
    "        failureReason = response.get(\"FailureReason\", \"\")\n",
    "        raise SystemExit(\n",
    "            f\"Failed to create feature group {feature_group.name}, status: {status}, reason: {failureReason}\"\n",
    "        )\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "wait_for_feature_group_creation_complete(feature_group=player_churn_feature_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b815d9",
   "metadata": {},
   "source": [
    "### Feature Store에 데이터 수집\n",
    "\n",
    "마지막으로, 처리된 데이터를 특성 그룹에 수집하겠습니다. 이렇게 하면 다음과 같은 용도로 특성을 사용할 수 있게 됩니다:\n",
    "- 새 모델 훈련\n",
    "- 실시간 추론\n",
    "- 특성 탐색 및 분석\n",
    "- 다른 팀과의 공유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c38f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest data into the feature group\n",
    "player_churn_feature_group.ingest(data_frame=df_balanced, max_workers=3, wait=True)\n",
    "print(f\"Ingested {len(df_balanced)} records into feature group {feature_group_name}\")\n",
    "\n",
    "# Describe the feature group to verify\n",
    "feature_group_details = player_churn_feature_group.describe()\n",
    "print(f\"\\nFeature Group Details:\\n{feature_group_details}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af085054",
   "metadata": {},
   "source": [
    "## 결론\n",
    "\n",
    "이 노트북에서는 플레이어 이탈 데이터셋에 대한 포괄적인 특성 공학을 수행했습니다:\n",
    "\n",
    "1. 가장 관련성 있는 특성 선택\n",
    "2. 결측값 처리\n",
    "3. 범주형 변수에 원-핫 인코딩 적용\n",
    "4. 오버샘플링을 사용하여 데이터셋 균형 맞추기\n",
    "5. ML 알고리즘과의 호환성을 위한 데이터 타입 변환\n",
    "6. ML 워크플로우에서 재사용하기 위해 SageMaker Feature Store에 특성 저장\n",
    "\n",
    "처리된 데이터는 이제 모델 훈련 및 평가를 위한 준비가 완료되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e5b21a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
