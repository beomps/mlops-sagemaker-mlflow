{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f489f2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4단계: 배포 파이프라인 추가하기\n",
    "이전 네 단계에서 자동화된 데이터 처리 및 모델 구축 파이프라인을 구현했습니다. 파이프라인의 각 실행은 새로운 버전의 모델을 생성합니다. 이 노트북은 ML 워크플로우에서 자동화된 모델 배포 단계를 구현합니다.\n",
    "\n",
    "![](img/sagemaker-mlops-project-deploy-diagram.jpg)\n",
    "\n",
    "[SageMaker MLOps 프로젝트 템플릿](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-templates.html)을 사용하여 바로 사용할 수 있는 모델 배포 CI/CD 파이프라인을 프로비저닝할 수 있습니다.\n",
    "\n",
    "이 템플릿은 SageMaker 모델 레지스트리의 모델을 실시간 추론을 위한 SageMaker 엔드포인트에 배포하는 과정을 자동화합니다. 이 템플릿은 모델 레지스트리의 변경 사항을 인식합니다. 새 모델 버전이 등록되고 승인되면 자동으로 배포를 시작합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2172390e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\"> 이 노트북에서는 JupyterLab의 <code>Python 3</code> 커널을 사용하고 있는지 확인하세요.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295887af",
   "metadata": {},
   "source": [
    "먼저, 이 노트북에 필요한 Python 종속성을 설치해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27673328",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install jsonlines tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0ac402",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker \n",
    "from time import gmtime, strftime, sleep\n",
    "import json\n",
    "import os\n",
    "from sagemaker.predictor import Predictor\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa14e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6637f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1565f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(model_package_group_name) > 0\n",
    "assert len(region) > 0\n",
    "assert len(bucket_name) > 0\n",
    "assert len(bucket_prefix) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b0af4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c5f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(project_name)\n",
    "    print(project_id)\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"You must complete the notebook 06-sagemaker-project\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79905ad1",
   "metadata": {},
   "source": [
    "## Studio UI에서 프로젝트 살펴보기\n",
    "\n",
    "<div class=\"alert alert-info\">6단계 노트북을 실행하고 MLOps 프로젝트를 성공적으로 프로비저닝하고 프로젝트 파이프라인을 최소 한 번 실행했는지 확인하세요.</div>\n",
    "\n",
    "다음 코드 셀에서 생성된 링크를 클릭하여 Studio UI에서 프로젝트와 모델 패키지를 확인하세요. 모델 패키지 그룹에 등록된 모델 버전이 최소 하나 이상 있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de601c63",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check that the project exists\n",
    "project_data = sm.describe_project(ProjectName=project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e1353",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert project_data['ProjectStatus'] == 'CreateCompleted', 'Project must be created at this point!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa46a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that at least one model version is registered in the model registry\n",
    "model_packages = sm.list_model_packages(\n",
    "    ModelPackageGroupName=f'{project_name}-{project_id}',\n",
    "    ModelApprovalStatus='PendingManualApproval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f49226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(model_packages['ModelPackageSummaryList']) > 0, 'You must have at least one model version in the status PendingManualApproval'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e29a4d",
   "metadata": {},
   "source": [
    "## 모델 배포를 위한 MLOps 프로젝트 작업하기\n",
    "이 템플릿은 모델 배포 단계를 지정하는 구성 파일, 인프라로서의 엔드포인트를 정의하는 AWS CloudFormation 템플릿, 그리고 엔드포인트 테스트를 위한 시드 코드가 포함된 CodeCommit 리포지토리를 프로비저닝합니다.\n",
    "\n",
    "이 템플릿은 다음과 같은 리소스를 제공합니다:\n",
    "\n",
    "1. 스테이징 및 프로덕션 환경에 모델을 엔드포인트에 배포하는 템플릿 코드가 포함된 AWS CodeCommit 리포지토리\n",
    "2. `source`, `build`, `deploy-to-staging`, `deploy-to-production` 단계가 있는 AWS CodePipeline 파이프라인. `source` 단계는 CodeCommit 리포지토리를 가리키고, `build` 단계는 해당 리포지토리에서 코드를 가져와 배포할 CloudFormation 스택을 생성합니다. `deploy-to-staging` 및 `deploy-to-production` 단계는 각 환경에 CloudFormation 스택을 배포합니다. 스테이징과 프로덕션 빌드 단계 사이에는 수동 승인 단계가 있어 MLOps 엔지니어가 프로덕션에 배포하기 전에 모델을 승인해야 합니다.\n",
    "3. 모델 패키지 버전이 승인되거나 거부될 때 CodePipeline 파이프라인 실행을 시작하는 Amazon EventBridge 규칙.\n",
    "4. 자리표시자 단위 테스트 이후에도 수동 승인 단계가 있습니다. 자리표시자 테스트를 대체하여 자체 테스트를 구현할 수 있습니다.\n",
    "\n",
    "이 템플릿은 또한 CodePipeline 및 CodeBuild 아티팩트, SageMaker 파이프라인 실행에서 생성된 아티팩트를 포함한 아티팩트를 저장하기 위한 Amazon S3 버킷을 배포합니다.\n",
    "\n",
    "다음 다이어그램은 아키텍처를 보여줍니다.\n",
    "\n",
    "<img src=\"img/mlops-model-deploy.png\" width=\"600\"/>\n",
    "\n",
    "프로젝트에 대한 구성 변경을 구현할 필요가 없습니다. 모델 배포 파이프라인은 즉시 작동합니다.\n",
    "모델 배포 파이프라인을 시작하려면 모델 레지스트리에서 모델 버전을 승인해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7352c8",
   "metadata": {},
   "source": [
    "### 모델 버전 승인하기\n",
    "모델 버전을 승인하면 MLOps 프로젝트가 모델 배포 프로세스를 시작합니다.\n",
    "\n",
    "첫 번째 단계에서 모델 배포 파이프라인은 모델 버전을 스테이징 SageMaker 실시간 추론 엔드포인트에 배포합니다.\n",
    "\n",
    "Studio의 모델 레지스트리에서 또는 노트북에서 프로그래밍 방식으로 모델 버전을 승인할 수 있습니다. 프로그래밍 방식으로 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7efda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(model_package_group_name)\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"Run the step 03 notebook to create a pipeline, run the pipeline, and register a model version in the model registry\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c6f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list all model packages and select the latest one\n",
    "model_packages = []\n",
    "\n",
    "for p in sm.get_paginator('list_model_packages').paginate(\n",
    "        ModelPackageGroupName=model_package_group_name,\n",
    "        SortBy=\"CreationTime\",\n",
    "        SortOrder=\"Descending\",\n",
    "    ):\n",
    "    model_packages.extend(p[\"ModelPackageSummaryList\"])\n",
    "\n",
    "if len(model_packages) == 0:\n",
    "    raise Exception(f\"No model package is found for {model_package_group_name} model package group. Run a model creation pipeline first.\")\n",
    "\n",
    "print(f\"There are {len(model_packages)} model versions in the {model_package_group_name} model package group\")\n",
    "print(f\"Approve the most recent model package:\")\n",
    "\n",
    "latest_model_package_arn = model_packages[0][\"ModelPackageArn\"]\n",
    "print(latest_model_package_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685ca21",
   "metadata": {},
   "source": [
    "다음 명령문은 모델 레지스트리에서 가장 최근 모델 패키지의 `ModelApprovalStatus`를 `Approved`로 설정합니다. 모델 패키지 상태 변경은 EventBridge 규칙을 시작하고, 이 규칙은 모델 배포가 포함된 CodePipeline CI/CD 파이프라인을 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907c94e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package_update_response = sm.update_model_package(\n",
    "    ModelPackageArn=latest_model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f89e6f",
   "metadata": {},
   "source": [
    "Studio UI의 모델 레지스트리에서 마지막 모델 버전의 **Status**가 `Approved`로 변경된 것을 확인할 수 있습니다:\n",
    "\n",
    "![](img/model-package-group-version-approval.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fb33d",
   "metadata": {},
   "source": [
    "### 배포 파이프라인 실행\n",
    "위의 코드 셀에서 모델 버전이 승인되면 모델 배포 CI/CD 파이프라인은 다음 작업을 수행합니다:\n",
    "1. SageMaker 엔드포인트 IaC가 포함된 CloudFormation 템플릿에 대한 스테이징 및 프로덕션 매개변수가 있는 CloudFormation 매개변수 구성 파일 생성\n",
    "1. 현재 계정에 `<PROJECT-NAME>-staging` 이름의 SageMaker 실시간 추론 엔드포인트 생성\n",
    "1. 스테이징 엔드포인트에서 테스트 스크립트 실행\n",
    "1. [AWS CodePipeline 콘솔](https://console.aws.amazon.com/codesuite/codepipeline)에서 테스트 결과가 수동으로 승인될 때까지 대기\n",
    "1. 현재 계정에 `<PROJECT-NAME>-prod` 이름의 SageMaker 엔드포인트 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45152f6",
   "metadata": {},
   "source": [
    "파이프라인이 스테이징 엔드포인트 배포를 완료할 때까지 약 10-15분 정도 기다리세요. Studio UI의 **Deployments** > **Endpoints**에서 엔드포인트 상태를 확인할 수 있습니다:\n",
    "\n",
    "![](img/sagemaker-mlops-deploy-endpoint-status.jpg)\n",
    "\n",
    "엔드포인트 상태가 `Creating`에서 `InService`로 변경되면 스테이징 엔드포인트가 완전히 작동합니다. CodePipeline 파이프라인의 **DeployStaging** 단계를 수동으로 승인하여 프로덕션 단계로의 모델 배포 프로세스를 시작할 수 있습니다. 다음 섹션에서는 모델 배포를 승인하고 프로덕션 엔드포인트로의 배포 두 번째 단계를 시작합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad0512a",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <p style=\" text-align: center; margin: auto;\">스테이징 엔드포인트 상태가 InService로 변경될 때까지 기다린 후 다음 코드 셀을 계속 진행하세요.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c97cc8",
   "metadata": {},
   "source": [
    "# SageMaker 엔드포인트 테스트하기\n",
    "스테이징에서 SageMaker 엔드포인트로의 성공적인 배포 후, 몇 가지 추론을 실행하여 엔드포인트를 검증해 보겠습니다.\n",
    "모델을 엔드포인트에서 제공할 때 Sagemaker는 다양한 옵션을 제공합니다:\n",
    "\n",
    "## SageMaker 엔드포인트\n",
    "SageMaker는 배포의 기술적 범위와 깊이에 대한 선택권을 제공하며 추론 사용 사례에 대한 다양한 옵션을 제공합니다:\n",
    "\n",
    "* **모델을 엔드포인트에 배포하기.** 모델을 배포할 때 다음 옵션을 고려하세요:\n",
    "   + [실시간 추론](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html). 실시간 추론은 대화형, 낮은 지연 시간 요구사항이 있는 추론 워크로드에 이상적입니다.\n",
    "   + [Amazon SageMaker Serverless Inference로 모델 배포](https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html). Serverless Inference를 사용하여 기본 인프라를 구성하거나 관리하지 않고 모델을 배포하세요. 이 옵션은 트래픽 급증 사이에 유휴 기간이 있고 콜드 스타트를 허용할 수 있는 워크로드에 이상적입니다.\n",
    "   + [비동기 추론](https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference.html). 들어오는 요청을 대기열에 넣고 비동기적으로 처리합니다. 이 옵션은 큰 페이로드 크기(최대 1GB), 긴 처리 시간(최대 한 시간), 그리고 거의 실시간 지연 요구사항이 있는 요청에 이상적입니다.\n",
    "\n",
    "* **비용 최적화**. 추론 비용을 최적화하려면 다음 옵션을 고려하세요:\n",
    "\n",
    "   + [Amazon SageMaker 모델 자동 확장](https://docs.aws.amazon.com/sagemaker/latest/dg/endpoint-auto-scaling.html). 자동 확장을 사용하여 들어오는 트래픽 패턴에 따라 엔드포인트의 컴퓨팅 리소스를 동적으로 조정하세요. 이는 특정 시점에 사용 중인 리소스에 대해서만 비용을 지불하므로 비용을 최적화하는 데 도움이 됩니다.\n",
    " \n",
    "다음 다이어그램은 SageMaker의 모든 배포 옵션에 대한 개요를 제공합니다:\n",
    "\n",
    "![](img/sagemaker-deployment-modes.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a71b04",
   "metadata": {},
   "source": [
    "## SageMaker 엔드포인트에서의 실시간 추론\n",
    "추론 기능을 시연하기 위해 이 노트북에서는 실시간 추론과 배치 변환을 모두 살펴보겠습니다. 프로덕션 환경에 배포하기 전에 엔드포인트가 예상대로 작동하는지 확인하기 위해 테스트에 스테이징 엔드포인트를 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all deployed real-time endpoints\n",
    "endpoints = sm.list_endpoints(StatusEquals=\"InService\")[\"Endpoints\"]\n",
    "\n",
    "if not len(endpoints):\n",
    "    print(\"There are no deployed active endpoints. You must have at least one endpoint. Run the previous cell in this notebook to deploy an endpoint\")\n",
    "else:\n",
    "    print(f\"Found {len(endpoints)} active inference endpoint(s):\\n\")\n",
    "    \n",
    "    for i, endpoint in enumerate(endpoints, 1):\n",
    "        print(f\"{i}. Endpoint Name: {endpoint['EndpointName']}\")\n",
    "        print(f\"   Status: {endpoint['EndpointStatus']}\")\n",
    "        print(f\"   Creation Time: {endpoint['CreationTime']}\")\n",
    "        print(f\"   Last Modified: {endpoint['LastModifiedTime']}\")\n",
    "        print(\"---\")\n",
    "    \n",
    "    # If you still need to select one endpoint for further operations, \n",
    "    # you can use the first one or add selection logic:\n",
    "    endpoint_name = endpoints[0]['EndpointName']\n",
    "    print(f\"\\nUsing endpoint '{endpoint_name}' for subsequent operations.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42841020",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> 강사 주도 교육으로 이 워크숍을 진행하는 경우, `endpoint_name`이 이미 설정되어 있으므로 별도로 할 일이 없습니다. 그렇지 않은 경우, 테스트에 적합한 endpoint_name으로 업데이트하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e18ca",
   "metadata": {},
   "source": [
    "### 헬퍼 함수 정의하기\n",
    "이 노트북 전체에서 사용할 코드 스니펫이 포함된 몇 가지 헬퍼 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e21a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send data to the endpoint\n",
    "def realtime_prediction(predictor, data):\n",
    "    l = len(data)\n",
    "    for i in trange(l):\n",
    "        data_arr = [float(np_float) for np_float in data.iloc[i].values ]\n",
    "        predictions = np.array(predictor.predict(data_arr), dtype=float).squeeze()\n",
    "        print(predictions)\n",
    "\n",
    "def download_from_s3(s3_client, local_file_path, bucket_name, s3_file_path):\n",
    "    try:\n",
    "        # Download the file\n",
    "        s3_client.download_file(bucket_name, s3_file_path, local_file_path)\n",
    "        print(f\"File downloaded successfully to {local_file_path}\")\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            print(\"The object does not exist.\")\n",
    "        else:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "def upload_to_s3(s3_client, local_file_path, bucket_name, s3_file_path=None):\n",
    "    # If S3 file path is not specified, use the basename of the local file\n",
    "    if s3_file_path is None:\n",
    "        s3_file_path = os.path.basename(local_file_path)\n",
    "\n",
    "    try:\n",
    "        # Upload the file\n",
    "        s3_client.upload_file(local_file_path, bucket_name, s3_file_path)\n",
    "        print(f\"File {local_file_path} uploaded successfully to {bucket_name}/{s3_file_path}\")\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        print(f\"ClientError: {e}\")\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {local_file_path} was not found\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return False\n",
    "        \n",
    "def write_params(s3_client, step_name, params, notebook_param_s3_bucket_prefix):\n",
    "    local_file_path = f\"{step_name}.json\"\n",
    "    with open(local_file_path, \"w\") as f:\n",
    "        f.write(json.dumps(params))\n",
    "    base_local_file_path = os.path.basename(local_file_path)\n",
    "    bucket_name = notebook_param_s3_bucket_prefix.split(\"/\")[2] # Format: s3://<bucket_name>/..\n",
    "    s3_file_path = os.path.join(\"/\".join(notebook_param_s3_bucket_prefix.split(\"/\")[3:]), base_local_file_path)\n",
    "    upload_to_s3(s3_client, local_file_path, bucket_name, s3_file_path)\n",
    "    \n",
    "def read_params(s3_client, notebook_param_s3_bucket_prefix, step_name):\n",
    "    local_file_path = f\"{step_name}.json\"\n",
    "    base_local_file_path = os.path.basename(local_file_path)\n",
    "    bucket_name = notebook_param_s3_bucket_prefix.split(\"/\")[2] # Format: s3://<bucket_name>/..\n",
    "    s3_file_path = os.path.join(\"/\".join(notebook_param_s3_bucket_prefix.split(\"/\")[3:]),  base_local_file_path)\n",
    "    downloaded = download_from_s3(s3_client, local_file_path, bucket_name, s3_file_path)\n",
    "    with open(local_file_path, \"r\") as f:\n",
    "        data = f.read()\n",
    "        params = json.loads(data)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea7af6e",
   "metadata": {},
   "source": [
    "### 테스트 데이터를 기반으로 실시간 예측 생성하기\n",
    "다음 셀에서는 이전 노트북에서 캡처한 테스트 데이터를 사용하여 실시간으로 몇 가지 추론을 실행하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e06247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a predictor class for the endpoint\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd4b849",
   "metadata": {},
   "source": [
    "In [02-preprocess.ipynb](02-preprocess.ipynb) we divided the dataset into training, validation and test dataset. For this lab, we'll use the test dataset for running inferences against the deployed endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a584fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_step_name = \"02-preprocess\"\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "notebook_param_s3_bucket_prefix=f\"s3://{bucket_name}/{bucket_prefix}/params\"\n",
    "preprocess_step_params = read_params(s3_client, notebook_param_s3_bucket_prefix, preprocess_step_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_test_x_file_path = \"test_x.csv\"\n",
    "local_test_y_file_path = \"test_y.csv\"\n",
    "s3_test_x_data = preprocess_step_params[\"test_x_data\"]\n",
    "s3_test_y_data = preprocess_step_params[\"test_y_data\"]\n",
    "\n",
    "# Download the test_x.csv and test_y.csv file from S3\n",
    "bucket_name = s3_test_x_data.split(\"/\")[2]\n",
    "s3_test_x_data_key = \"/\".join(s3_test_x_data.split(\"/\")[3:])\n",
    "s3_test_y_data_key = \"/\".join(s3_test_y_data.split(\"/\")[3:])\n",
    "download_from_s3(s3_client, local_test_x_file_path, bucket_name, s3_test_x_data_key)\n",
    "download_from_s3(s3_client, local_test_y_file_path, bucket_name, s3_test_y_data_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of data vectors from the test dataset sent to the inference endpoint as batch\n",
    "number_of_vectors = 10\n",
    "test_x = pd.read_csv(\"test_x.csv\", header=None).sample(number_of_vectors)\n",
    "\n",
    "# Select only the first 10 features (columns 0-9) to match the trained model\n",
    "test_x = test_x.iloc[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dbed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the output to see the response payload\n",
    "print(f\"Test data shape after feature selection: {test_x.shape}\")\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969fc2b",
   "metadata": {},
   "source": [
    "Rename the column names for identifying the feature attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ebf068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x will have 10 columns\n",
    "test_x.columns = [f'_c{i}' for i in range(len(test_x.columns))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe2ecc",
   "metadata": {},
   "source": [
    "Run prediction using the realtime endpoint deployed in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime_prediction(predictor, test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a0e5a",
   "metadata": {},
   "source": [
    "# Batch Transform\n",
    "SageMaker offers [batch transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) to optimize inference workloads for the following  scenarios:\n",
    "\n",
    "* Preprocess datasets to remove noise or bias that interferes with training or inference from your dataset.\n",
    "* Get inferences from large datasets.\n",
    "* Run inference when you don't need a persistent endpoint.\n",
    "* Associate input records with inferences to help with the interpretation of results.\n",
    "\n",
    "Functionally, batch transform uses the same mechanics as real-time hosting to generate predictions. It requires a web server that takes in HTTP POST requests a single observation, or mini-batch, at a time. However, unlike real-time hosted endpoints which have persistent hardware (instances stay running until you shut them down), batch transform clusters are torn down when the job completes.\n",
    "\n",
    "To demonstrate the capability, we'll run a batch transform job on the same dataset that we used for realtime inference previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595ab16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and preprocess the test data to use only first 10 features\n",
    "import pandas as pd\n",
    "\n",
    "# Download the original test data\n",
    "local_test_x_batch_file = \"test_x_batch_full.csv\"\n",
    "download_from_s3(s3_client, local_test_x_batch_file, bucket_name, s3_test_x_data_key)\n",
    "\n",
    "# Load and select only first 10 features\n",
    "test_x_full = pd.read_csv(local_test_x_batch_file, header=None)\n",
    "test_x_batch = test_x_full.iloc[:, :10]  # Select only first 10 features\n",
    "\n",
    "print(f\"Original batch data shape: {test_x_full.shape}\")\n",
    "print(f\"Modified batch data shape: {test_x_batch.shape}\")\n",
    "\n",
    "# Save the modified test data locally\n",
    "local_test_x_batch_processed = \"test_x_batch_processed.csv\"\n",
    "test_x_batch.to_csv(local_test_x_batch_processed, header=False, index=False)\n",
    "\n",
    "# Upload the processed data to S3\n",
    "s3_test_x_batch_processed_key = f\"{bucket_prefix}/test/test_x_batch_processed.csv\"\n",
    "s3_test_x_batch_processed_path = f\"s3://{bucket_name}/{s3_test_x_batch_processed_key}\"\n",
    "\n",
    "s3_client.upload_file(\n",
    "    local_test_x_batch_processed, \n",
    "    bucket_name, \n",
    "    s3_test_x_batch_processed_key\n",
    ")\n",
    "\n",
    "print(f\"Processed batch data uploaded to: {s3_test_x_batch_processed_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3080d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.inputs import TransformInput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54aa131",
   "metadata": {},
   "source": [
    "먼저 배포된 SageMaker 엔드포인트에서 model_name을 가져오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1125be",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm.describe_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")\n",
    "endpoint_config_name = response[\"EndpointConfigName\"]\n",
    "response = sm.describe_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "model_name = response['ProductionVariants'][0]['ModelName']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6bd288",
   "metadata": {},
   "source": [
    "배치 변환 작업을 실행하기 위한 batch_transform 변수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b77d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_transform_instance_type = \"ml.m5.large\"\n",
    "batch_transform_output_path = f\"s3://{bucket_name}/{bucket_prefix}/transform\"\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ed37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transform step\n",
    "transformer = Transformer(\n",
    "        model_name=model_name,\n",
    "        instance_type=batch_transform_instance_type,\n",
    "        instance_count=1,\n",
    "        accept=\"text/csv\",\n",
    "        assemble_with=\"Line\",\n",
    "        output_path=batch_transform_output_path,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        base_transform_job_name=f\"player-churn-model-batch-transform\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9babaa75",
   "metadata": {},
   "source": [
    "SageMaker Python SDK를 사용하여 배치 변환 작업을 트리거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17810fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the processed data with only 10 features instead of original data\n",
    "transformer.transform(    \n",
    "        data=s3_test_x_batch_processed_path,  # Changed from s3_test_x_data\n",
    "        content_type=\"text/csv\",\n",
    "        split_type=\"Line\", \n",
    "        join_source=\"Input\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ef36b",
   "metadata": {},
   "source": [
    "S3 버킷에서 추론 결과를 다운로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66075be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $transformer.output_path ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb4269",
   "metadata": {},
   "source": [
    "페이로드를 살펴보겠습니다. 예측 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a464ea",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> 위의 결과는 입력 데이터와 CSV 형식의 예측이 포함된 응답 페이로드를 보여줍니다. 페이로드에는 입력과 예측 레이블이 모두 포함되어 있습니다. 기본 출력 구조 외에도 배치 변환이 출력을 구성하는 방식을 사용자 지정할 수 있습니다. 이러한 사용자 지정에 대해 자세히 알아보려면 이 [링크](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#batch-transform-data-processing-examples)를 참조하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -10 test_x_batch_processed.csv.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2fa0d0",
   "metadata": {},
   "source": [
    "### 모델 버전을 프로덕션에 배포\n",
    "스테이징 엔드포인트를 검증하고 결과에 만족했다고 가정하면, 이제 배포 파이프라인을 계속해서 프로덕션 배포를 진행하겠습니다.\n",
    "\n",
    "CodePipeline 승인 링크를 생성해 보겠습니다.\n",
    "\n",
    "옵션 1 `boto3`를 사용하여 MLOps 프로젝트를 생성한 경우, `project_name` 및 `project_id`가 자동으로 설정됩니다. 다음 코드 셀을 실행하여 값을 출력할 수 있습니다. UI 지침에 따라 프로젝트를 생성한 경우 `project_name`을 수동으로 설정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65322a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(project_name)\n",
    "    print(project_id)\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"You must set the project_name manually\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c0385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set to the model deployment project name if you didn't use boto3-based deployment\n",
    "# project_name = \"<PROJECT_NAME>\"\n",
    "\n",
    "# Get project id\n",
    "project_id = sm.describe_project(ProjectName=project_name)['ProjectId']\n",
    "\n",
    "# Construct the CodePipline pipeline name\n",
    "code_pipeline_name = f\"sagemaker-{project_name}-{project_id}-modeldeploy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    " # approve the latest model version\n",
    "model_package_update_response = sm.update_model_package(\n",
    "    ModelPackageArn=latest_model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb71a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "# Show the approval link\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Please approve the manual step in <a target=\"top\" href=\"https://console.aws.amazon.com/codesuite/codepipeline/pipelines/{}/view?region={}\">AWS CodePipeline</a></b>'.format(\n",
    "            code_pipeline_name, region)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080b3655",
   "metadata": {},
   "source": [
    "위의 ^^^ 링크 ^^^를 클릭하여 파이프라인 실행 워크플로우가 있는 CodePipeline 콘솔을 엽니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe4831",
   "metadata": {},
   "source": [
    "**DeployStaging 단계**에서 **ApproveDeployment** 단계의 **Review**를 선택합니다. `TestStaging` 단계가 `Succeeded` 상태로 완료될 때까지 기다려야 할 수 있습니다.\n",
    "\n",
    "![](img/deploy-staging-review.png)\n",
    "\n",
    "**Review** 대화 상자에서 **Approve**를 선택하고 **Submit**을 클릭합니다:\n",
    "\n",
    "![](img/approve-deployment.png)\n",
    "\n",
    "**DeployStaging** 단계를 승인하면 배포 파이프라인이 계속 진행되어 모델을 프로덕션 엔드포인트에 배포합니다. 엔드포인트를 보려면 Studio UI에서 **Deployments** > **Endpoints**를 선택하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc04fa8",
   "metadata": {},
   "source": [
    "CI/CD 배포 파이프라인이 계속 진행됨에 따라 이전에 배포된 스테이징 엔드포인트가 `InService` 상태인 동안 프로덕션 엔드포인트가 `Creating` 상태인 것을 볼 수 있습니다:\n",
    "\n",
    "![](img/endpoint-prod-creating.png)\n",
    "\n",
    "`10-15`분 후 배포가 완료되고 두 엔드포인트 모두 `InService` 상태가 됩니다.\n",
    "\n",
    "Studio로 이동하여 **Deployments** > **Projects**를 선택합니다. Project 창에서 `model-deploy-<TIMESTAMP>` 프로젝트를 선택합니다. 프로젝트 세부 정보 창에서 **Endpoints**를 선택합니다. 프로젝트와 엔드포인트가 메타데이터를 통해 연결되어 있기 때문에 `staging`과 `prod` 두 엔드포인트 모두 배포 프로젝트에 표시됩니다:\n",
    "\n",
    "![](img/project-endpoints.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2083d5",
   "metadata": {},
   "source": [
    "## 요약\n",
    "이 노트북에서는 다음 기능을 갖춘 자동화된 CI/CD 배포 파이프라인을 구현했습니다:\n",
    "- SageMaker 실시간 추론 엔드포인트 배포를 위한 CloudFormation IaC 템플릿 사용\n",
    "- 모델 레지스트리의 모델 승인이 모델 배포 파이프라인을 시작\n",
    "- 모델 배포 파이프라인에는 스테이징 엔드포인트에 대한 자동화된 테스트와 프로덕션 배포를 위한 수동 승인이 포함된 두 단계(스테이징 및 프로덕션)가 포함됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff105917",
   "metadata": {},
   "source": [
    "## 정리\n",
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <p style=\" text-align: center; margin: auto;\">\n",
    "    6단계 노트북(데이터 및 모델 품질 모니터링)을 실행할 예정이라면 엔드포인트 중 하나 이상을 유지해야 합니다. 여기서 워크숍을 마치고 6단계 노트북을 실행하지 않을 경우, <b>정리 노트북(99-clean-up.ipynb)</b>으로 이동하여 정리 지침을 따라 AWS 계정에서 요금이 발생하지 않도록 하세요.\n",
    "    <br>\n",
    "    <br>\n",
    "    AWS에서 제공한 AWS 계정을 사용하는 경우에는 정리를 실행할 필요가 없습니다.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0fc267",
   "metadata": {},
   "source": [
    "## 실제 프로젝트를 위한 추가 개발 아이디어\n",
    "- AWS KMS 키를 사용한 엔드-투-엔드 데이터 암호화 추가\n",
    "- 특정 프로젝트 요구 사항을 충족하기 위한 모델 배포용 [사용자 지정 SageMaker 프로젝트 템플릿](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-templates-custom.html) 생성\n",
    "- ML 워크플로우에 [다중 계정 모델 배포](https://aws.amazon.com/blogs/machine-learning/multi-account-model-deployment-with-amazon-sagemaker-pipelines/) 추가\n",
    "- CodePipeline 파이프라인의 플레이스홀더에 자동화된 모델 테스트 추가\n",
    "- [Amazon SageMaker Inference Recommender](https://docs.aws.amazon.com/sagemaker/latest/dg/inference-recommender.html)를 사용하여 추론 엔드포인트에 대한 자동화된 부하 테스트를 실행하고 최적의 인스턴스 유형 및 구성 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7875f46",
   "metadata": {},
   "source": [
    "## 추가 리소스\n",
    "- [실시간 추론 엔드포인트에 머신 러닝 모델 배포](https://aws.amazon.com/getting-started/hands-on/machine-learning-tutorial-deploy-model-to-real-time-inference-endpoint/)\n",
    "- [SageMaker MLOps 프로젝트 안내](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-walkthrough.html)\n",
    "- [SageMaker Immersion Day의 Amazon SageMaker Pipelines 랩](https://catalog.us-east-1.prod.workshops.aws/workshops/63069e26-921c-4ce1-9cc7-dd882ff62575/en-US/lab6)\n",
    "- [Amazon SageMaker 보안 MLOps](https://github.com/aws-samples/amazon-sagemaker-secure-mlops)\n",
    "- [Amazon SageMaker ML 모델을 위한 테스트 접근 방식](https://aws.amazon.com/blogs/machine-learning/testing-approaches-for-amazon-sagemaker-ml-models/)\n",
    "- [Amazon SageMaker의 모델 호스팅 패턴 블로그 시리즈](https://aws.amazon.com/blogs/machine-learning/model-hosting-patterns-in-amazon-sagemaker-part-1-common-design-patterns-for-building-ml-applications-on-amazon-sagemaker/)\n",
    "- [Amazon SageMaker 배포 가드레일을 활용한 고급 배포 전략](https://aws.amazon.com/blogs/machine-learning/take-advantage-of-advanced-deployment-strategies-using-amazon-sagemaker-deployment-guardrails/)\n",
    "- [Amazon SageMaker를 사용한 실시간 추론 모델 서빙 엔드포인트를 위한 MLOps 배포 모범 사례](https://aws.amazon.com/blogs/machine-learning/mlops-deployment-best-practices-for-real-time-inference-model-serving-endpoints-with-amazon-sagemaker/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3ee14",
   "metadata": {},
   "source": [
    "# 커널 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
